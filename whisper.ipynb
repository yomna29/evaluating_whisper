{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f35fa7",
   "metadata": {},
   "source": [
    "Creating conda environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f620ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install git+https://github.com/openai/whisper.git \n",
    "#!pip install setuptools-rust\n",
    "#!CALL C:\\Users\\yyomn\\Anaconda3\\Scripts\\activate.bat whisper_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7638adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Whisper BasicTextNormalizer\n",
      "torch.cuda.is_available() = True\n",
      "Loading Whisper model on device: cuda\n",
      "Model actual device: cuda:0\n",
      "\n",
      "=== Evaluating: ar/_ ===\n",
      "Detected language: Arabic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65604/65604 [00:41<00:00, 1586.99frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: ar\n",
      "  WER: 0.336 | CER: 0.096\n",
      "[WARN] Missing reference.txt: data\\ar\\Five_Steps_to_Create_a_New_AI_Model\\reference.txt\n",
      "\n",
      "=== Evaluating: de/US-Gesandter_auf_Putins_Seite_DW_Nachrichten ===\n",
      "Detected language: German\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40300/40300 [00:13<00:00, 3086.83frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: de\n",
      "  WER: 0.053 | CER: 0.015\n",
      "\n",
      "=== Evaluating: de/Was_ist_los_im_Sudan_analyse ===\n",
      "Detected language: German\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90653/90653 [00:36<00:00, 2517.18frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: de\n",
      "  WER: 0.050 | CER: 0.013\n",
      "\n",
      "=== Evaluating: es/Que_significa_Quien_pudiera_y_como_se_usa_Espanol_directo_al_grano ===\n",
      "Detected language: Spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 46646/46646 [00:14<00:00, 3245.14frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: es\n",
      "  WER: 0.009 | CER: 0.004\n",
      "\n",
      "=== Evaluating: es/Vlog_2_-_Dia_de_las_velitas_en_Colombia._Bunuelos_y_tamal# ===\n",
      "Detected language: Spanish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141469/141469 [00:52<00:00, 2697.55frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: es\n",
      "  WER: 0.287 | CER: 0.243\n",
      "\n",
      "=== Evaluating: fr/Biarritz_-_la_Californie_francaise ===\n",
      "Detected language: French\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81013/81013 [00:28<00:00, 2806.73frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: fr\n",
      "  WER: 0.062 | CER: 0.046\n",
      "\n",
      "=== Evaluating: fr/Ne_dites_pas_J_ai_deux# ===\n",
      "Detected language: French\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63061/63061 [00:22<00:00, 2840.46frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: fr\n",
      "  WER: 0.034 | CER: 0.025\n",
      "\n",
      "=== Evaluating: zh/How_to_Survive_in_China_as_an_Introvert_or_Extrovert_Learn_Chinese_Through_Vlogs ===\n",
      "Detected language: Chinese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91422/91422 [00:33<00:00, 2735.05frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: zh\n",
      "  WER: 0.982 | CER: 0.331\n",
      "[WARN] Missing reference.txt: data\\zh\\Slow_Chinese_Vlog_What_I_Eat_in_a_Day_comprehensible_input_HSK1-3\\reference.txt\n",
      "\n",
      "=== Evaluating: zh/Why_Chinese_Prefer_Big_Hospitals_Learn_Chinese_Through_Vlogs ===\n",
      "Detected language: Chinese\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70949/70949 [00:23<00:00, 3066.65frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Detected language: zh\n",
      "  WER: 1.000 | CER: 0.188\n",
      "\n",
      "Results written to results\\whisper_eval_results.csv\n"
     ]
    }
   ],
   "source": [
    "# scripts/evaluate_whisper.pyS\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import unicodedata\n",
    "from pathlib import Path\n",
    "from typing import Tuple, List\n",
    "\n",
    "import torch\n",
    "import whisper\n",
    "\n",
    "\n",
    "DATA_ROOT = Path(\"data\")\n",
    "RESULTS_DIR = Path(\"results\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RESULTS_CSV = RESULTS_DIR / \"whisper_eval_results.csv\"\n",
    "\n",
    "\n",
    "# Try to use Whisper's normalizer if available; otherwise, use a fallback\n",
    "def build_normalizer():\n",
    "    try:\n",
    "        from whisper.normalizers import BasicTextNormalizer\n",
    "        print(\"Using Whisper BasicTextNormalizer\")\n",
    "        normalizer = BasicTextNormalizer()\n",
    "\n",
    "        def normalize(text: str) -> str:\n",
    "            return normalizer(text)\n",
    "\n",
    "        return normalize\n",
    "    except Exception:\n",
    "        print(\"Whisper normalizer not found; using simple fallback normalizer\")\n",
    "\n",
    "        def normalize(text: str) -> str:\n",
    "            # Lowercase\n",
    "            text = text.lower()\n",
    "            # Unicode normalization\n",
    "            text = unicodedata.normalize(\"NFKC\", text)\n",
    "            # Remove most punctuation but keep letters/numbers in all languages\n",
    "            text = re.sub(r\"[^\\w\\s]\", \" \", text, flags=re.UNICODE)\n",
    "            # Collapse whitespace\n",
    "            text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "            return text\n",
    "\n",
    "        return normalize\n",
    "\n",
    "\n",
    "NORMALIZE = build_normalizer()\n",
    "\n",
    "\n",
    "def levenshtein_distance(ref: List[str], hyp: List[str]) -> int:\n",
    "    \"\"\"Standard Levenshtein distance on token lists.\"\"\"\n",
    "    n, m = len(ref), len(hyp)\n",
    "    dp = [[0] * (m + 1) for _ in range(n + 1)]\n",
    "\n",
    "    for i in range(n + 1):\n",
    "        dp[i][0] = i\n",
    "    for j in range(m + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = 0 if ref[i - 1] == hyp[j - 1] else 1\n",
    "            dp[i][j] = min(\n",
    "                dp[i - 1][j] + 1,      # deletion\n",
    "                dp[i][j - 1] + 1,      # insertion\n",
    "                dp[i - 1][j - 1] + cost,  # substitution\n",
    "            )\n",
    "    return dp[n][m]\n",
    "\n",
    "\n",
    "def compute_wer(ref: str, hyp: str) -> float:\n",
    "    ref_tokens = ref.split()\n",
    "    hyp_tokens = hyp.split()\n",
    "    if len(ref_tokens) == 0:\n",
    "        return 0.0 if len(hyp_tokens) == 0 else 1.0\n",
    "    dist = levenshtein_distance(ref_tokens, hyp_tokens)\n",
    "    return dist / len(ref_tokens)\n",
    "\n",
    "\n",
    "def compute_cer(ref: str, hyp: str) -> float:\n",
    "    # Optionally we can remove spaces; here we keep them\n",
    "    ref_chars = list(ref)\n",
    "    hyp_chars = list(hyp)\n",
    "    if len(ref_chars) == 0:\n",
    "        return 0.0 if len(hyp_chars) == 0 else 1.0\n",
    "    dist = levenshtein_distance(ref_chars, hyp_chars)\n",
    "    return dist / len(ref_chars)\n",
    "\n",
    "\n",
    "def iter_samples():\n",
    "    \"\"\"\n",
    "    Iterate over data/<lang_dir>/<video_dir>/\n",
    "    and yield (lang_dir_name, video_dir_name, audio_path, ref_txt_path).\n",
    "\n",
    "    We:\n",
    "      - Look for any *.wav inside each video_dir\n",
    "      - Expect a reference.txt in the same folder\n",
    "    \"\"\"\n",
    "    for lang_dir in sorted(DATA_ROOT.iterdir()):\n",
    "        if not lang_dir.is_dir():\n",
    "            continue\n",
    "        lang_code = lang_dir.name\n",
    "\n",
    "        for video_dir in sorted(lang_dir.iterdir()):\n",
    "            if not video_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "            # Find the .wav file (yt-dlp names it with the title)\n",
    "            audio_candidates = sorted(video_dir.glob(\"*.wav\"))\n",
    "            if not audio_candidates:\n",
    "                print(f\"[WARN] No .wav file found in: {video_dir}\")\n",
    "                continue\n",
    "\n",
    "            audio_path = audio_candidates[0]  # first .wav in that folder\n",
    "            ref_txt_path = video_dir / \"reference.txt\"\n",
    "\n",
    "            if not ref_txt_path.exists():\n",
    "                print(f\"[WARN] Missing reference.txt: {ref_txt_path}\")\n",
    "                continue\n",
    "\n",
    "            yield lang_code, video_dir.name, audio_path, ref_txt_path\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    # ---- Load Whisper model on GPU if available ----\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    print(f\"torch.cuda.is_available() = {torch.cuda.is_available()}\")\n",
    "    print(f\"Loading Whisper model on device: {device}\")\n",
    "\n",
    "    model = whisper.load_model(\"turbo\", device=device)\n",
    "    print(f\"Model actual device: {next(model.parameters()).device}\")\n",
    "\n",
    "    # ---- CSV setup ----\n",
    "    with RESULTS_CSV.open(\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"lang_folder\",\n",
    "            \"video_folder\",\n",
    "            \"whisper_detected_lang\",\n",
    "            \"wer\",\n",
    "            \"cer\",\n",
    "            \"ref_len_chars\",\n",
    "            \"hyp_len_chars\",\n",
    "            \"ref_norm\",\n",
    "            \"hyp_norm\",\n",
    "        ])\n",
    "\n",
    "        for lang_folder, video_folder, audio_path, ref_txt_path in iter_samples():\n",
    "            print(f\"\\n=== Evaluating: {lang_folder}/{video_folder} ===\")\n",
    "\n",
    "            # Load reference text\n",
    "            ref_raw = ref_txt_path.read_text(encoding=\"utf-8\").strip()\n",
    "            ref_norm = NORMALIZE(ref_raw)\n",
    "\n",
    "            # Whisper transcription with automatic language detection\n",
    "            result = model.transcribe(\n",
    "                str(audio_path),\n",
    "                task=\"transcribe\",\n",
    "                language=None,        # let Whisper detect\n",
    "                verbose=False,\n",
    "            )\n",
    "\n",
    "            hyp_raw = result.get(\"text\", \"\").strip()\n",
    "            hyp_norm = NORMALIZE(hyp_raw)\n",
    "            detected_lang = result.get(\"language\", \"\")\n",
    "\n",
    "            wer = compute_wer(ref_norm, hyp_norm)\n",
    "            cer = compute_cer(ref_norm, hyp_norm)\n",
    "\n",
    "            print(f\"  Detected language: {detected_lang}\")\n",
    "            print(f\"  WER: {wer:.3f} | CER: {cer:.3f}\")\n",
    "\n",
    "            writer.writerow([\n",
    "                lang_folder,\n",
    "                video_folder,\n",
    "                detected_lang,\n",
    "                f\"{wer:.6f}\",\n",
    "                f\"{cer:.6f}\",\n",
    "                len(ref_norm),\n",
    "                len(hyp_norm),\n",
    "                ref_norm,\n",
    "                hyp_norm,\n",
    "            ])\n",
    "\n",
    "    print(f\"\\nResults written to {RESULTS_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
